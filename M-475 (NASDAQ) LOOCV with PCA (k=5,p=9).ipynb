{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.metrics import hamming_loss\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleMatrix(matrix):\n",
    "    return matrix.div(matrix.sum(axis=1),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(series):\n",
    "    b = max(series)\n",
    "    a = min(series)\n",
    "    return [(x - a) / (b - a) for x in series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npmc(init_state, matrix, original_states, init_state_col):\n",
    "    matrix = scaleMatrix(matrix)\n",
    "    probs = {k:list(matrix.iloc[original_states.index(k)]) for k in original_states}\n",
    "    NewState = []\n",
    "    for x in range(len(init_state)):\n",
    "        NewState.append(np.random.choice(a = matrix.columns, p = probs[init_state[init_state_col][x]],size=1)[0])\n",
    "    NextStep = pd.DataFrame()\n",
    "    NextStep[\"Original State\"] = init_state[init_state_col]\n",
    "    NextStep[\"New State\"] = NewState\n",
    "    return NextStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chain(init_state, matrix, original_states, init_state_col,n):\n",
    "    init_state = init_state.copy()\n",
    "    out = pd.DataFrame()\n",
    "    out[0] = init_state[init_state_col]\n",
    "    for i in range(1,n+1):\n",
    "        out[i] = npmc(out,matrix,original_states,i-1)[\"New State\"]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proj(inp,X1,X2,n,start_state_col):\n",
    "    sts = []\n",
    "    inp.reset_index(drop = True,inplace = True)\n",
    "    curr_st = inp[start_state_col].iloc[0]\n",
    "    for step in range(n):\n",
    "        sts.append(curr_st)\n",
    "        if curr_st == -1:\n",
    "            try:\n",
    "                up_prob = npdfd[\"t1\"].iloc[downknn.kneighbors([[inp[X1][step],inp[X2][step]]],n_neighbors,False)[0]].value_counts()[1] / n_neighbors\n",
    "            except:\n",
    "                up_prob = 0\n",
    "            try:\n",
    "                down_prob = npdfd[\"t1\"].iloc[downknn.kneighbors([[inp[X1][step],inp[X2][step]]],n_neighbors,False)[0]].value_counts()[0] / n_neighbors\n",
    "            except:\n",
    "                down_prob = 1- up_prob\n",
    "            curr_st = np.random.choice([0,1],1,p = [down_prob, up_prob])[0]\n",
    "        else:\n",
    "            try:\n",
    "                up_prob = npdfu[\"t1\"].iloc[upknn.kneighbors([[inp[X1][step],inp[X2][step]]],n_neighbors,False)[0]].value_counts()[1] / n_neighbors\n",
    "            except:\n",
    "                up_prob = 0\n",
    "            try:\n",
    "                down_prob = npdfu[\"t1\"].iloc[upknn.kneighbors([[inp[X1][step],inp[X2][step]]],n_neighbors,False)[0]].value_counts()[0] / n_neighbors\n",
    "            except:\n",
    "                down_prob = 1 - up_prob\n",
    "            curr_st = np.random.choice([0,1],1,p = [down_prob, up_prob])[0]\n",
    "    return sts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick = pd.read_csv(\"NASDAQ_Ticks.csv\")\n",
    "all_data = {}\n",
    "all_tm = {}\n",
    "returns = {}\n",
    "for x in tick[\"Ticker\"]:\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    t0 = pd.read_csv(x+\".csv\")[\"Adj Close\"]\n",
    "    returns[x] = t0.pct_change().iloc[::3][1:]\n",
    "    df[\"MMYYYY\"] = [x[5:7] + x[:4] for x in pd.read_csv(x+\".csv\")[\"Date\"][1:]]\n",
    "    df.reset_index(drop = True,inplace = True)\n",
    "    df[\"t0\"] = np.where(t0.pct_change()[1:] > 0, 1, 0)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    df[\"t1\"] = df[\"t0\"].shift(-3)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    states = [\"Up\",\"Down\"]\n",
    "    TM = pd.DataFrame(index = [\"Up\",\"Down\"])\n",
    "    \n",
    "    tm = {\"UU\":0,\"UD\":0,\"DU\":0,\"DD\":0}\n",
    "    \n",
    "    for i in range(2,len(df)):\n",
    "        \n",
    "        if df[\"t0\"][i] == 1 and df[\"t0\"][i-1] == 1:\n",
    "            tm[\"UU\"] += 1\n",
    "        elif df[\"t0\"][i] == 0 and df[\"t0\"][i-1] == 1:\n",
    "            tm[\"UD\"] += 1\n",
    "        elif df[\"t0\"][i] == 1 and df[\"t0\"][i-1] == 0:\n",
    "            tm[\"DU\"] += 1\n",
    "        else:\n",
    "            tm[\"DD\"] += 1\n",
    "            \n",
    "    TM[\"Up\"] = [tm[\"UU\"],tm[\"UD\"]]\n",
    "    TM[\"Down\"] = [tm[\"DU\"],tm[\"DD\"]]\n",
    "    \n",
    "    findf = pd.read_csv(x + \"_quarterly_valuation_measures.csv\",header=None).T\n",
    "    findf.columns = findf.iloc[0]\n",
    "    findf.drop([0,1],inplace=True)\n",
    "    \n",
    "    findf1 = pd.DataFrame()\n",
    "    findf1[\"MMYYYY\"] = [y[:2]+ y[6:10] for y in findf[\"name\"].str.replace('/', '-')]\n",
    "    try:\n",
    "        findf1[\"PeRatio\"] = np.log(findf[\"PeRatio\"].str.replace(',', '').astype(float))\n",
    "    except:\n",
    "        findf1[\"PeRatio\"] = np.log(findf[\"PegRatio\"].str.replace(',', '').astype(float)*0.18)\n",
    "    findf1[\"PsRatio\"] = np.log(findf[\"PsRatio\"].str.replace(',', '').astype(float))\n",
    "    findf1[\"PbRatio\"] = np.log(findf[\"PbRatio\"].str.replace(',', '').astype(float))\n",
    "    findf1['MarketCap'] = np.log(findf['MarketCap'].str.replace(',', '').astype(float))\n",
    "    findf1.interpolate(method='linear',inplace=True)\n",
    "    \n",
    "    findf1.dropna(inplace=True)\n",
    "    findf1.reset_index(drop = True,inplace = True)\n",
    "    \n",
    "    alldf = df.merge(right=findf1, on = [\"MMYYYY\"])\n",
    "    if len(alldf) > 5:\n",
    "        all_tm[x] = scaleMatrix(TM)\n",
    "        all_data[x] = alldf\n",
    "len(all_data)\n",
    "for x in all_data.keys():\n",
    "    pca = PCA(n_components=1)\n",
    "    all_data[x][\"Z\"] = pca.fit_transform(all_data[x][[\"PeRatio\",\"PsRatio\",\"PbRatio\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npdf = pd.DataFrame()\n",
    "tk = []\n",
    "my = []\n",
    "t0 = []\n",
    "t1 = []\n",
    "mc = []\n",
    "z = []\n",
    "for x in all_data.keys():\n",
    "    tk.extend([x for y in range(len(all_data[x]))])\n",
    "    my.extend([x for x in all_data[x][\"MMYYYY\"]])\n",
    "    t0.extend([x for x in all_data[x][\"t0\"]])\n",
    "    t1.extend([x for x in all_data[x][\"t1\"]])\n",
    "    z.extend([x for x in all_data[x][\"Z\"]])\n",
    "    mc.extend([x for x in all_data[x][\"MarketCap\"]])\n",
    "npdf[\"Ticker\"] = tk\n",
    "npdf[\"MMYYYY\"] = my\n",
    "npdf[\"t0\"] = t0\n",
    "npdf[\"t1\"] = t1\n",
    "npdf[\"Z\"] = z\n",
    "npdf[\"MarketCap\"] = mc\n",
    "npdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_out = pd.DataFrame()\n",
    "final_out[\"Ticker\"] = list(all_data.keys())\n",
    "testerrorqties = {}\n",
    "for g in range(len(all_data)):\n",
    "    if g in [1,23,46,68]:\n",
    "        print(str(100*g / len(all_data))+\"% done!\")\n",
    "    test_comps = [list(all_data.keys())[g]]\n",
    "    test = npdf.iloc[np.where(npdf[\"Ticker\"] == test_comps[0])]\n",
    "    train = npdf.iloc[np.where(npdf[\"Ticker\"] != test_comps[0])]\n",
    "    train.reset_index(drop = True,inplace = True)\n",
    "    test.reset_index(drop = True,inplace = True)\n",
    "    npdfu = train.loc[npdf[\"t0\"] == 1]\n",
    "    npdfd = train.loc[npdf[\"t0\"] == 0]\n",
    "    n_neighbors = 5\n",
    "    scale = pd.DataFrame()\n",
    "    scale[\"MarketCap\"] = norm(npdfu[\"MarketCap\"])\n",
    "    scale[\"Z\"] = norm(npdfu[\"Z\"])\n",
    "    upknn = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "    X = scale[[\"MarketCap\",\"Z\"]]\n",
    "    y = npdfu[\"t1\"]\n",
    "    upknn.fit(X,y)\n",
    "    scale = pd.DataFrame()\n",
    "    scale[\"MarketCap\"] = norm(npdfd[\"MarketCap\"])\n",
    "    scale[\"Z\"] = norm(npdfd[\"Z\"])\n",
    "    downknn = neighbors.KNeighborsClassifier(n_neighbors)\n",
    "    X = scale[[\"MarketCap\",\"Z\"]]\n",
    "    y = npdfd[\"t1\"]\n",
    "    downknn.fit(X,y)\n",
    "    p = 9\n",
    "    k = 0\n",
    "    TEST1 = {}\n",
    "    test1 = test.loc[test[\"Ticker\"] == test_comps[0]][[\"t0\",\"t1\",\"Z\",\"MarketCap\"]]\n",
    "    test1.reset_index(drop = True,inplace = True)\n",
    "    i=0\n",
    "    while p+k <= len(test1):\n",
    "        TEST1[i] = test1.iloc[k:p+k]\n",
    "        k+=1\n",
    "        i+=1\n",
    "    np.random.seed(10)\n",
    "    testloss = []\n",
    "    n = 100\n",
    "    for j in range(len(TEST1)):\n",
    "        for i in range(n):\n",
    "            out = proj(TEST1[j],\"Z\",\"MarketCap\",len(TEST1[j]),\"t0\")\n",
    "            testloss.append(hamming_loss(out[1:],TEST1[j][\"t1\"][1:]))\n",
    "    TM = pd.DataFrame(index = [1,0])\n",
    "\n",
    "    tm = {\"UU\":0,\"UD\":0,\"DU\":0,\"DD\":0}\n",
    "\n",
    "    for x in all_data.keys():\n",
    "        if x not in test_comps:\n",
    "            tm[\"UU\"] += all_tm[x][\"Up\"][\"Up\"]\n",
    "            tm[\"DU\"] += all_tm[x][\"Down\"][\"Up\"]\n",
    "            tm[\"UD\"] += all_tm[x][\"Up\"][\"Down\"]\n",
    "            tm[\"DD\"] += all_tm[x][\"Down\"][\"Down\"]\n",
    "    TM[1] = [tm[\"UU\"],tm[\"UD\"]]\n",
    "    TM[0] = [tm[\"DU\"],tm[\"DD\"]]\n",
    "    TM = scaleMatrix(TM)\n",
    "    np.random.seed(10)\n",
    "    ptstest1 = {}\n",
    "    for i in range(len(TEST1)):\n",
    "        ptstest1[i] = pd.DataFrame()\n",
    "        ptstest1[i][\"t0\"] = [TEST1[i][\"t0\"][0]]\n",
    "    ptsloss = []\n",
    "    for j in range(len(TEST1)):\n",
    "        for i in range(n):\n",
    "            out = chain(init_state = ptstest1[j], matrix = TM, original_states = [1,0], init_state_col = \"t0\",n=len(TEST1[j])-1)\n",
    "            ptsloss.append(hamming_loss(out.iloc[0][1:],TEST1[j][\"t1\"][1:]))\n",
    "    f = plt.figure(g)\n",
    "    sns.kdeplot(testloss,shade=True)\n",
    "    sns.kdeplot(ptsloss,shade=True)\n",
    "    plt.xlabel(\"Loss\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend([\"Test Chain Loss \"+str(test_comps[0]),\"Markov Chain Loss \"+str(test_comps[0])])\n",
    "    plt.show()\n",
    "    testerrorqties[test_comps[0]] = {\"Proposed Model\":[x for x in pd.Series(testloss).describe(percentiles = [0.1+0.1*i for i in range(9)])],\"Pure Time Series\":[x for x in pd.Series(ptsloss).describe(percentiles = [0.1+0.1*i for i in range(9)])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testerrorqties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"count\":0, \n",
    " \"mean\":1,\n",
    " \"std\":2,\n",
    " \"min\":3,\n",
    " \"0.1\":4,\n",
    " \"0.2\":5,\n",
    " \"0.3\":6,\n",
    " \"0.4\":7,\n",
    " \"0.5\":8,\n",
    " \"0.6\":9,\n",
    " \"0.7\":10,\n",
    " \"0.8\":11,\n",
    " \"0.9\":12,\n",
    " \"max\":13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctreductionloss = []\n",
    "avgcap = []\n",
    "avgpe = []\n",
    "q = 1\n",
    "for x in testerrorqties.keys():\n",
    "    l = (testerrorqties[x][\"Pure Time Series\"][q] - testerrorqties[x][\"Proposed Model\"][q]) / testerrorqties[x][\"Pure Time Series\"][q]\n",
    "    pctreductionloss.append(l)\n",
    "    print(l)\n",
    "    avgcap.append(all_data[x][\"MarketCap\"][len(all_data[x])-1])\n",
    "    avgpe.append(all_data[x][\"Z\"][len(all_data[x])-1])\n",
    "lossdf = pd.DataFrame()\n",
    "lossdf[\"Reduction\"] = pctreductionloss\n",
    "lossdf[\"Average MktCap\"] = avgcap\n",
    "lossdf[\"Average P/E\"] = avgpe\n",
    "lossdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossdf.loc[lossdf[\"Reduction\"] <= 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossdf.loc[lossdf[\"Reduction\"] > 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure()\n",
    "f.set_figwidth(15)\n",
    "f.set_figheight(15)\n",
    "plt.scatter(lossdf[\"Average MktCap\"],lossdf[\"Average P/E\"],c = lossdf[\"Reduction\"],cmap=\"Blues\",s = 100)\n",
    "plt.xlabel(\"Market Cap\",c=\"white\")\n",
    "plt.ylabel(\"P/E Ratio\",c=\"white\")\n",
    "plt.title(\"Decrease in Loss\",loc=\"left\",c=\"white\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossdf[\"Reduction\"].describe(percentiles = [0.1+0.1*i for i in range(9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(lossdf[\"Reduction\"],density=True,bins=40)\n",
    "sns.kdeplot(lossdf[\"Reduction\"],shade=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
